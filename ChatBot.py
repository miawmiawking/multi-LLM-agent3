import requests
import streamlit as st
from langchain_community.tools import DuckDuckGoSearchRun
import PyPDF2
from docx import Document
import chardet
import base64
import io
from langchain.docstore.document import Document as LC_Document # æ–°å¢ langchain ç›¸å…³ä¾èµ–
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain.llms import HuggingFaceHub
import tempfile
import os
from pydub import AudioSegment
from openai import OpenAI
from bs4 import BeautifulSoup
from duckduckgo_search import DDGS
import re
from urllib.parse import urlparse
import csv

# å…¨å±€å˜é‡å®šä¹‰
CHROMADB_PATH = None
COLLECTION_NAME = "rag_collection"

# ChromaDB é…ç½®å‡½æ•°
def configure_chromadb():
    st.divider()
    with st.expander("ğŸ—„ï¸ RAGçŸ¥è¯†åº“è®¾ç½®", expanded=not bool(st.session_state.get("chromadb_path"))):
        st.markdown("### ChromaDBå­˜å‚¨è·¯å¾„")
        
        # æ˜¾ç¤ºå½“å‰è·¯å¾„
        current_path = st.session_state.get("chromadb_path", "")
        if current_path:
            st.info(f"å½“å‰è·¯å¾„ï¼š{current_path}")
            
            # æ·»åŠ æ¸…ç©ºæ•°æ®åº“æŒ‰é’®
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºçŸ¥è¯†åº“", key="clear_db"):
                try:
                    # è·å–å‘é‡åº“å®ä¾‹
                    vectorstore = get_vector_store()
                    if vectorstore:
                        # åˆ é™¤æ‰€æœ‰æ–‡æ¡£
                        vectorstore.delete_collection()
                        vectorstore = None
                        st.session_state.vector_store = None
                        st.session_state.rag_data = []
                        st.success("âœ… çŸ¥è¯†åº“å·²æ¸…ç©º")
                        st.experimental_rerun()
                except Exception as e:
                    st.error(f"âŒ æ¸…ç©ºçŸ¥è¯†åº“å¤±è´¥ï¼š{str(e)}")
        
        # è·¯å¾„è¾“å…¥
        default_path = os.path.join(os.path.expanduser("~"), "chromadb_data")
        new_path = st.text_input(
            "è®¾ç½®å­˜å‚¨è·¯å¾„",
            value=current_path or default_path,
            placeholder="ä¾‹å¦‚ï¼šC:/Users/YourName/Documents/chromadb",
            key="chromadb_path_input"
        )
        
        # ç¡®è®¤æŒ‰é’®
        if st.button("âœ… ç¡®è®¤è·¯å¾„", key="confirm_chromadb_path"):
            try:
                # ç¡®ä¿è·¯å¾„å­˜åœ¨
                os.makedirs(new_path, exist_ok=True)
                
                # æµ‹è¯•è·¯å¾„æ˜¯å¦å¯å†™
                test_file = os.path.join(new_path, "test_write.txt")
                try:
                    with open(test_file, "w") as f:
                        f.write("test")
                    os.remove(test_file)
                except Exception as e:
                    st.error(f"è·¯å¾„æ— å†™å…¥æƒé™ï¼š{str(e)}")
                    return
                
                # æ›´æ–°è·¯å¾„
                st.session_state.chromadb_path = new_path
                # æ›´æ–°å…¨å±€å˜é‡
                global CHROMADB_PATH
                CHROMADB_PATH = new_path
                
                st.success("âœ… ChromaDBè·¯å¾„è®¾ç½®æˆåŠŸï¼")
                st.session_state.vector_store = None  # é‡ç½®å‘é‡åº“å®ä¾‹
                
            except Exception as e:
                st.error(f"âŒ è·¯å¾„è®¾ç½®å¤±è´¥ï¼š{str(e)}")
        
        st.markdown("""
        **è¯´æ˜ï¼š**
        1. é¦–æ¬¡ä½¿ç”¨è¯·è®¾ç½®å­˜å‚¨è·¯å¾„
        2. è·¯å¾„éœ€è¦æœ‰å†™å…¥æƒé™
        3. å»ºè®®é€‰æ‹©æœ¬åœ°å›ºå®šä½ç½®
        4. ç¡®ä¿æœ‰è¶³å¤Ÿå­˜å‚¨ç©ºé—´
        """)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "messages" not in st.session_state:
    st.session_state.messages = []
if "search_enabled" not in st.session_state:
    st.session_state.search_enabled = False
if "file_analyzed" not in st.session_state:
    st.session_state.file_analyzed = False
if "file_content" not in st.session_state:
    st.session_state.file_content = ""
if "file_summary" not in st.session_state:
    st.session_state.file_summary = ""
if "selected_model" not in st.session_state:
    st.session_state.selected_model = "è±†åŒ…"
if "selected_function" not in st.session_state:
    st.session_state.selected_function = "æ™ºèƒ½é—®ç­”"
if "api_keys" not in st.session_state:
    st.session_state.api_keys = {}
if "rag_enabled" not in st.session_state:
    st.session_state.rag_enabled = False
if "rag_data" not in st.session_state:
    st.session_state.rag_data = []
if "temperature" not in st.session_state:
    st.session_state.temperature = 0.5
if "max_tokens" not in st.session_state:
    st.session_state.max_tokens = 2048
if "chromadb_path" not in st.session_state:
    st.session_state.chromadb_path = ""
if "vector_store" not in st.session_state:
    st.session_state.vector_store = None

# é¡µé¢é…ç½®
st.set_page_config(page_title="å¤šæ¨¡å‹æ™ºèƒ½åŠ©æ‰‹2.0", layout="wide")

# åˆå§‹åŒ–/åŠ è½½ langchain å°è£…çš„ Chroma å‘é‡åº“
def get_vector_store():
    """è·å–æˆ–åˆ›å»ºå‘é‡æ•°æ®åº“å®ä¾‹"""
    # æ£€æŸ¥æ˜¯å¦å·²è®¾ç½®è·¯å¾„
    if not st.session_state.get("chromadb_path"):
        st.error("âš ï¸ è¯·å…ˆåœ¨ä¾§è¾¹æ è®¾ç½® ChromaDB å­˜å‚¨è·¯å¾„ï¼")
        return None
    
    try:
        # åˆå§‹åŒ– embeddings
        embeddings = HuggingFaceEmbeddings(
            model_name="all-MiniLM-L6-v2",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        
        # åˆ›å»ºå‘é‡åº“å®ä¾‹
        vectorstore = Chroma(
            collection_name=COLLECTION_NAME,
            embedding_function=embeddings,
            persist_directory=st.session_state.chromadb_path
        )
        
        # æ£€æŸ¥é›†åˆæ˜¯å¦ä¸ºç©º
        if vectorstore._collection.count() == 0:
            st.warning("âš ï¸ çŸ¥è¯†åº“ä¸ºç©ºï¼Œè¯·å…ˆä¸Šä¼ æ–‡ä»¶æˆ–ç½‘å€ã€‚")
            return None
            
        return vectorstore
        
    except Exception as e:
        st.error(f"âŒ åˆå§‹åŒ–å‘é‡åº“å¤±è´¥ï¼š{str(e)}")
        return None

# åˆå§‹åŒ– DuckDuckGo æœç´¢å·¥å…·
search_tool = DuckDuckGoSearchRun()

# æ ¸å¿ƒåŠŸèƒ½å®ç°

def handle_web_search(query):
    """è”ç½‘æœç´¢åŠŸèƒ½ï¼Œä½¿ç”¨ DuckDuckGo API"""
    if not st.session_state.search_enabled:
        return None
    try:
        search = DuckDuckGoSearchRun()
        results = search.run(query)
        return results
    except Exception as e:
        st.error(f"è”ç½‘æœç´¢å¤±è´¥: {str(e)}")
        return None

def call_model_api(prompt, model_type, rag_data=None):
    """è°ƒç”¨é™¤ RAG éƒ¨åˆ†å¤–çš„å…¶ä»–æ¥å£"""
    headers = {"Content-Type": "application/json"}
    try:
        if model_type == "è±†åŒ…":
            api_key = st.session_state.api_keys.get("è±†åŒ…", "")
            if not api_key:
                st.error("è¯·æä¾›è±†åŒ… API å¯†é’¥ï¼")
                return None
            headers["Authorization"] = f"Bearer {api_key}"
            response = requests.post(
                "https://ark.cn-beijing.volces.com/api/v3/chat/completions",
                json={
                    "model": "ep-20250128163906-p4tb5",
                    "messages": [
                        {"role": "system", "content": "You are a helpful assistant."},
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": st.session_state.temperature,
                    "max_tokens": st.session_state.max_tokens
                },
                headers=headers
            )
            return handle_response(response, rag_data)
        elif model_type == "DeepSeek-V3":
            api_key = st.session_state.api_keys.get("DeepSeek", "")
            if not api_key:
                st.error("è¯·æä¾› DeepSeek API å¯†é’¥ï¼")
                return None
            headers["Authorization"] = f"Bearer {api_key}"
            response = requests.post(
                "https://api.deepseek.com/v1/chat/completions",
                json={
                    "model": "deepseek-chat",
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": st.session_state.temperature,
                    "max_tokens": st.session_state.max_tokens
                },
                headers=headers
            )
            return handle_response(response, rag_data)
        elif model_type == "é€šä¹‰åƒé—®":
            api_key = st.session_state.api_keys.get("é€šä¹‰åƒé—®", "")
            if not api_key:
                st.error("è¯·æä¾› é€šä¹‰åƒé—® API å¯†é’¥ï¼")
                return None
            headers["Authorization"] = f"Bearer {api_key}"
            response = requests.post(
                "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions",
                json={
                    "model": "qwen-plus",
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": st.session_state.temperature,
                    "max_tokens": st.session_state.max_tokens
                },
                headers=headers
            )
            return handle_response(response, rag_data)
        elif model_type == "æ–‡å¿ƒä¸€è¨€":
            api_key = st.session_state.api_keys.get("æ–‡å¿ƒä¸€è¨€", "")
            if not api_key:
                st.error("è¯·æä¾› æ–‡å¿ƒä¸€è¨€ API å¯†é’¥ï¼")
                return None
            headers["Authorization"] = f"Bearer {api_key}"
            response = requests.post(
                "https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/completions",
                json={
                    "model": "ERNIE-Bot",
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": st.session_state.temperature,
                    "max_tokens": st.session_state.max_tokens
                },
                headers=headers
            )
            return handle_response(response, rag_data)
        elif model_type == "æ™ºè°±æ¸…è¨€":
            api_key = st.session_state.api_keys.get("æ™ºè°±æ¸…è¨€", "")
            if not api_key:
                st.error("è¯·æä¾› æ™ºè°±æ¸…è¨€ API å¯†é’¥ï¼")
                return None
            headers["Authorization"] = f"Bearer {api_key}"
            response = requests.post(
                "https://open.bigmodel.cn/api/paas/v4/chat/completions",
                json={
                    "model": "glm-4",
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": st.session_state.temperature,
                    "max_tokens": st.session_state.max_tokens
                },
                headers=headers
            )
            return handle_response(response, rag_data)
        elif model_type == "MiniMax":
            api_key = st.session_state.api_keys.get("MiniMax", "")
            if not api_key:
                st.error("è¯·æä¾› MiniMax API å¯†é’¥ï¼")
                return None
            headers["Authorization"] = f"Bearer {api_key}"
            response = requests.post(
                "https://api.minimax.chat/v1/text/chatcompletion_v2",
                json={
                    "model": "abab5.5-chat",
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": st.session_state.temperature,
                    "max_tokens": st.session_state.max_tokens
                },
                headers=headers
            )
            return handle_response(response, rag_data)
        elif model_type == "DALL-E(æ–‡ç”Ÿå›¾)":
            api_key = st.session_state.api_keys.get("OpenAI", "")
            if not api_key:
                st.error("è¯·æä¾› DALL-E(æ–‡ç”Ÿå›¾) API å¯†é’¥ï¼")
                return None
            headers["Authorization"] = f"Bearer {st.session_state.api_keys['OpenAI']}"
            response = requests.post(
                "https://api.openai.com/v1/images/generations",
                json={
                    "prompt": prompt,
                    "n": 1,
                    "size": "512x512"
                },
                headers=headers
            )
            response_json = response.json()
            if "data" in response_json and len(response_json["data"]) > 0:
                image_url = response_json["data"][0]["url"]
                return image_url
            else:
                st.error(f"DALL-E API è¿”å›æ ¼å¼å¼‚å¸¸: {response_json}")
                return None
        elif model_type == "DeepSeek-R1(æ·±åº¦æ¨ç†)":
            api_key = st.session_state.api_keys.get("DeepSeek", "")
            if not api_key:
                st.error("è¯·æä¾› DeepSeek API å¯†é’¥ï¼")
                return None
            headers["Authorization"] = f"Bearer {api_key}"
            response = requests.post(
                "https://api.deepseek.com/v1/chat/completions",  # ä¿®æ”¹ä¸ºæ­£ç¡®çš„æ¥å£åœ°å€
                json={
                    "model": "deepseek-reasoner",  # ä¿®æ”¹ä¸ºæ­£ç¡®çš„æ¨¡å‹åç§°
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": st.session_state.temperature,
                    "max_tokens": st.session_state.max_tokens
                },
                headers=headers
            )
            return handle_response(response, rag_data)
        elif model_type == "o1(æ·±åº¦æ¨ç†)":
            api_key = st.session_state.api_keys.get("OpenAI", "")
            if not api_key:
                st.error("è¯·æä¾› o1 API å¯†é’¥ï¼")
                return None
            headers["Authorization"] = f"Bearer {api_key}"
            response = requests.post(
                "https://api.openai.com/v1/chat/completions",
                json={
                    "model": "o1-mini",
                    "messages": [{"role": "user", "content": prompt}],
                    "max_completion_tokens": st.session_state.max_tokens  # ä¿®æ”¹å‚æ•°åç§°
                },
                headers=headers
            )
            return handle_response(response, rag_data)
        elif model_type == "Kimi(è§†è§‰ç†è§£)":
            api_key = st.session_state.api_keys.get("Kimi(è§†è§‰ç†è§£)", "")
            if not api_key:
                st.error("è¯·æä¾› Kimi(è§†è§‰ç†è§£) API å¯†é’¥ï¼")
                return None
            headers["Authorization"] = f"Bearer {api_key}"
            
            # ç®€å•çš„æ–‡æœ¬æµ‹è¯•
            response = requests.post(
                "https://api.moonshot.cn/v1/chat/completions",
                json={
                    "model": "moonshot-v1-8k-vision-preview",
                    "messages": [
                        {
                            "role": "user",
                            "content": [
                                {
                                    "type": "text",
                                    "text": "è¯·å›å¤'APIè¿æ¥æ­£å¸¸'"
                                }
                            ]
                        }
                    ]
                },
                headers=headers
            )
            return handle_response(response)
        elif model_type == "GPTs(èŠå¤©ã€è¯­éŸ³è¯†åˆ«)":
            api_key = st.session_state.api_keys.get("OpenAI", "")
            if not api_key:
                st.error("è¯·æä¾› OpenAI API å¯†é’¥ï¼")
                return None
            headers["Authorization"] = f"Bearer {api_key}"
            response = requests.post(
                "https://api.openai.com/v1/chat/completions",
                json={
                    "model": "gpt-4o",
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": st.session_state.temperature,
                    "max_tokens": st.session_state.max_tokens
                },
                headers=headers
            )
            return handle_response(response, rag_data)
        else:
            # é»˜è®¤è°ƒç”¨ä½¿ç”¨ RAG ç”Ÿæˆç­”æ¡ˆï¼ˆä¸‹æ–‡ä½¿ç”¨ langchain å®ç°ï¼‰
            return rag_generate_response(prompt)
    except Exception as e:
        st.error(f"APIè°ƒç”¨å¤±è´¥: {str(e)}")
        return None

def handle_response(response, rag_data=None):
    """å¤„ç† API å“åº”"""
    try:
        if response.status_code == 200:
            response_json = response.json()
            if "choices" in response_json and len(response_json["choices"]) > 0:
                answer = response_json["choices"][0]["message"]["content"]
            elif "result" in response_json:
                # é’ˆå¯¹æ–‡å¿ƒä¸€è¨€è¿”å›æ ¼å¼å¤„ç†
                answer = response_json["result"]
            elif "data" in response_json and isinstance(response_json["data"], list) and len(response_json["data"]) > 0:
                # é’ˆå¯¹ DALL-E è¿”å›æ ¼å¼å¤„ç†
                if "url" in response_json["data"][0]:
                    answer = response_json["data"][0]["url"]
                else:
                    st.error(f"API è¿”å›æ ¼å¼å¼‚å¸¸: {response_json}")
                    return None
            else:
                st.error(f"API è¿”å›æ ¼å¼å¼‚å¸¸: {response_json}")
                return None

            if rag_data and isinstance(answer, str):  # ç¡®ä¿æ˜¯æ–‡æœ¬æ‰æ·»åŠ å¼•ç”¨
                answer += "\n\nå¼•ç”¨æ¥æºï¼š\n" + "\n".join([f"- {source}" for source in rag_data])
            return answer
        elif response.status_code == 503:
            st.error("æœåŠ¡å™¨ç¹å¿™ï¼Œè¯·ç¨åå†è¯•ã€‚")
            return None
        else:
            st.error(f"API è¯·æ±‚å¤±è´¥ï¼Œé”™è¯¯ç ï¼š{response.status_code}")
            return None
    except ValueError as e:
        st.error(f"å“åº”è§£æå¤±è´¥: {str(e)}")
        return None

# ä½¿ç”¨ langchain å®ç° RAGï¼šåŠ è½½æ–‡æ¡£ã€åˆ†å‰²ã€åµŒå…¥ã€ç´¢å¼•
def get_embeddings():
    """è·å– embeddings å®ä¾‹"""
    try:
        return HuggingFaceEmbeddings(
            model_name="all-MiniLM-L6-v2",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
    except Exception as e:
        st.error(f"åˆå§‹åŒ– embeddings å¤±è´¥ï¼š{str(e)}")
        return None

def rag_index_document(content, source):
    """å°†æ–‡æ¡£æ·»åŠ åˆ°å‘é‡æ•°æ®åº“"""
    try:
        # æ£€æŸ¥å†…å®¹å’Œè·¯å¾„
        if not content or not st.session_state.chromadb_path:
            st.error("âš ï¸ å†…å®¹ä¸ºç©ºæˆ–æœªè®¾ç½®å­˜å‚¨è·¯å¾„")
            return False
            
        # æ–‡æœ¬åˆ†å‰²
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len,
        )
        texts = text_splitter.split_text(content)
        
        if not texts:
            st.error("âš ï¸ æ–‡æœ¬åˆ†å‰²åä¸ºç©º")
            return False
            
        # è·å– embeddings
        embeddings = get_embeddings()
        if not embeddings:
            return False
        
        # åˆ›å»ºæˆ–è·å–å‘é‡åº“å®ä¾‹
        try:
            vectorstore = Chroma(
                collection_name=COLLECTION_NAME,
                embedding_function=embeddings,
                persist_directory=st.session_state.chromadb_path
            )
        except Exception as e:
            st.error(f"åˆ›å»ºå‘é‡åº“å®ä¾‹å¤±è´¥ï¼š{str(e)}")
            return False
        
        # ä¸ºæ¯ä¸ªæ–‡æœ¬å—æ·»åŠ æºä¿¡æ¯
        metadatas = [{"source": source} for _ in texts]
        
        # æ·»åŠ æ–‡æ¡£
        try:
            vectorstore.add_texts(
                texts=texts,
                metadatas=metadatas
            )
            vectorstore.persist()
            st.session_state.vector_store = vectorstore
            st.info(f"âœ… æˆåŠŸæ·»åŠ  {len(texts)} ä¸ªæ–‡æœ¬å—åˆ°çŸ¥è¯†åº“")
            return True
        except Exception as e:
            st.error(f"æ·»åŠ æ–‡æœ¬åˆ°å‘é‡åº“å¤±è´¥ï¼š{str(e)}")
            return False
            
    except Exception as e:
        st.error(f"âŒ æ·»åŠ æ–‡æ¡£åˆ°å‘é‡åº“å¤±è´¥ï¼š{str(e)}")
        import traceback
        st.error(f"è¯¦ç»†é”™è¯¯ï¼š{traceback.format_exc()}")
        return False

def rag_generate_response(query):
    """ç”Ÿæˆ RAG å“åº”"""
    # è·å–å‘é‡åº“å®ä¾‹
    vectorstore = get_vector_store()
    if not vectorstore:
        return "è¯·å…ˆä¸Šä¼ æ–‡ä»¶æˆ–ç½‘å€åˆ°çŸ¥è¯†åº“ã€‚"
    
    try:
        # æ‰§è¡Œç›¸ä¼¼æ€§æœç´¢
        docs = vectorstore.similarity_search(query, k=3)
        
        if not docs:
            return "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚è¯·å°è¯•è°ƒæ•´é—®é¢˜æˆ–æ·»åŠ æ›´å¤šç›¸å…³æ–‡æ¡£ã€‚"
        
        # æ„å»ºæç¤ºè¯
        context = "\n\n".join([doc.page_content for doc in docs])
        sources = "\n".join([f"- {doc.metadata.get('source', 'æœªçŸ¥æ¥æº')}" for doc in docs])
        
        prompt = f"""åŸºäºä»¥ä¸‹å‚è€ƒä¿¡æ¯å›ç­”é—®é¢˜ï¼š

å‚è€ƒä¿¡æ¯ï¼š
{context}

é—®é¢˜ï¼š{query}

è¯·æä¾›å‡†ç¡®ã€ç›¸å…³çš„å›ç­”ã€‚å¦‚æœå‚è€ƒä¿¡æ¯ä¸è¶³ä»¥å›ç­”é—®é¢˜ï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚
"""
        # è°ƒç”¨æ¨¡å‹ç”Ÿæˆå›ç­”
        response = call_model_api(prompt, st.session_state.selected_model)
        if response:
            return f"{response}\n\næ¥æºï¼š\n{sources}"
        return "ç”Ÿæˆå›ç­”å¤±è´¥ï¼Œè¯·é‡è¯•ã€‚"
    
    except Exception as e:
        st.error(f"âŒ ç”Ÿæˆå›ç­”å¤±è´¥ï¼š{str(e)}")
        return None

def handle_file_upload(uploaded_files):
    """å¤„ç†ä¸Šä¼ æ–‡ä»¶ï¼Œæ ¹æ® RAG çŠ¶æ€åŠæ–‡ä»¶ç±»å‹æ‰§è¡Œä¸åŒæ“ä½œï¼š
       - RAG æ¨¡å¼ä¸‹ï¼šæ–‡æœ¬ã€è¡¨æ ¼ç±»æ–‡ä»¶åŠ å…¥çŸ¥è¯†åº“ï¼›
       - é RAG æ¨¡å¼ä¸‹ï¼š
           å›¾ç‰‡æ–‡ä»¶ -> è§†è§‰åˆ†æ
           è¯­éŸ³æ–‡ä»¶ -> è¯­éŸ³è¯†åˆ«
           æ–‡æœ¬æ–‡ä»¶ -> æ–‡æœ¬æ€»ç»“
    """
    if not uploaded_files:
        return

    if not isinstance(uploaded_files, list):
        uploaded_files = [uploaded_files]

    for uploaded_file in uploaded_files:
        if not hasattr(uploaded_file, "name"):
            st.error("ä¸Šä¼ çš„æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œç¼ºå°‘åç§°å±æ€§ã€‚")
            continue

        file_name = uploaded_file.name
        file_type = uploaded_file.type.split("/")[-1].lower()
        try:
            if st.session_state.rag_enabled:
                # RAG æ¨¡å¼ä¸‹ï¼Œä»…å¤„ç†æ–‡æœ¬ã€è¡¨æ ¼ç±»æ–‡ä»¶åŠ å…¥çŸ¥è¯†åº“
                if file_type in ["txt", "pdf", "docx", "doc", "csv", "xlsx", "xls"]:
                    content = extract_text_from_file(uploaded_file)
                    if content:
                        if rag_index_document(content, file_name):
                            st.session_state.rag_data.append(file_name)
                            st.success(f"æ–‡ä»¶ {file_name} å·²æˆåŠŸåŠ å…¥ RAG çŸ¥è¯†åº“")
                else:
                    st.warning(f"RAG æ¨¡å¼ä¸‹ï¼Œæ–‡ä»¶ {file_name} çš„ç±»å‹ï¼ˆ{file_type}ï¼‰ä¸æ”¯æŒåŠ å…¥çŸ¥è¯†åº“ã€‚")
            else:
                # é RAG æ¨¡å¼ï¼Œæ ¹æ®æ–‡ä»¶ç±»å‹è°ƒç”¨å¯¹åº”åŠŸèƒ½
                if file_type in ["jpg", "jpeg", "png"]:
                    st.write(f"æ­£åœ¨åˆ†æå›¾ç‰‡ï¼š{file_name}")
                    analysis_result = perform_visual_analysis(uploaded_file.getvalue())
                    if analysis_result:
                        st.write("è§†è§‰åˆ†æç»“æœï¼š")
                        st.write(analysis_result)
                        st.session_state.messages.append({
                            "role": "assistant",
                            "content": f"å›¾ç‰‡åˆ†æç»“æœï¼š\n{analysis_result}",
                            "type": "text"
                        })
                elif file_type in ["mp3", "wav", "m4a", "mpeg"]:
                    st.write(f"æ­£åœ¨è¿›è¡Œè¯­éŸ³è¯†åˆ«ï¼š{file_name}")
                    speech_result = perform_speech_recognition(uploaded_file.getvalue())
                    if speech_result:
                        st.write("è¯­éŸ³è¯†åˆ«ç»“æœï¼š")
                        st.write(speech_result)
                        st.session_state.messages.append({
                            "role": "assistant",
                            "content": f"è¯­éŸ³è¯†åˆ«ç»“æœï¼š\n{speech_result}",
                            "type": "text"
                        })
                elif file_type in ["txt", "pdf", "docx", "doc"]:
                    content = extract_text_from_file(uploaded_file)
                    if content:
                        st.write(f"æ­£åœ¨æ€»ç»“æ–‡æœ¬ï¼š{file_name}")
                        summary_result = perform_text_summary(content)
                        if summary_result:
                            st.write("æ–‡æœ¬æ€»ç»“ç»“æœï¼š")
                            st.write(summary_result)
                            st.session_state.messages.append({
                                "role": "assistant",
                                "content": f"æ–‡æœ¬æ€»ç»“ç»“æœï¼š\n{summary_result}",
                                "type": "text"
                            })
                else:
                    st.warning(f"æ–‡ä»¶ {file_name} çš„ç±»å‹ï¼ˆ{file_type}ï¼‰ä¸æ”¯æŒå¤„ç†ã€‚")
        except Exception as e:
            st.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥ ({file_name}): {str(e)}")

def extract_text_from_file(file):
    """ä»ä¸åŒç±»å‹çš„æ–‡ä»¶ä¸­æå–æ–‡æœ¬"""
    try:
        file_type = file.name.split('.')[-1].lower()
        
        if file_type == 'txt':
            return file.getvalue().decode('utf-8')
            
        elif file_type == 'pdf':
            pdf_reader = PyPDF2.PdfReader(file)
            text = ''
            for page in pdf_reader.pages:
                text += page.extract_text() + '\n'
            return text
            
        elif file_type in ['docx', 'doc']:
            doc = Document(file)
            return '\n'.join([paragraph.text for paragraph in doc.paragraphs])
            
        elif file_type in ['csv']:
            return process_csv_file(file)
            
        elif file_type in ['xlsx', 'xls']:
            # å¦‚æœéœ€è¦å¤„ç† Excel æ–‡ä»¶ï¼Œå¯ä»¥ä½¿ç”¨ openpyxl
            import openpyxl
            wb = openpyxl.load_workbook(file)
            text = []
            for sheet in wb.sheetnames:
                ws = wb[sheet]
                for row in ws.rows:
                    text.append(' '.join(str(cell.value) for cell in row if cell.value))
            return '\n'.join(text)
            
        else:
            st.error(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼š{file_type}")
            return None
            
    except Exception as e:
        st.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥ï¼š{str(e)}")
        return None

def process_csv_file(file):
    content = []
    csv_data = file.read().decode('utf-8').splitlines()
    csv_reader = csv.reader(csv_data)
    for row in csv_reader:
        content.append(' '.join(row))
    return '\n'.join(content)

def perform_visual_analysis(image_content):
    """ä½¿ç”¨ moonshot-v1-8k-vision-preview æ¨¡å‹è¿›è¡Œè§†è§‰åˆ†æ"""
    try:
        api_key = st.session_state.api_keys.get("Kimi(è§†è§‰ç†è§£)")
        if not api_key:
            st.error("è¯·æä¾› Kimi(è§†è§‰ç†è§£) API å¯†é’¥ï¼")
            return None

        # å°†å›¾ç‰‡å†…å®¹ç¼–ç ä¸º base64 å­—ç¬¦ä¸²
        encoded_string = base64.b64encode(image_content).decode("utf-8")

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
        payload = {
            "model": "moonshot-v1-8k-vision-preview",
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": "è¯·æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ã€‚"
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{encoded_string}"
                            }
                        }
                    ]
                }
            ],
            "temperature": st.session_state.temperature,
            "max_tokens": st.session_state.max_tokens
        }

        response = requests.post(
            "https://api.moonshot.cn/v1/chat/completions",
            json=payload,
            headers=headers
        )
        return handle_response(response)
    except Exception as e:
        st.error(f"è§†è§‰åˆ†æå¤±è´¥: {str(e)}")
        return None

def perform_speech_recognition(audio_bytes):
    """
    ä½¿ç”¨å½“å‰é€‰æ‹©çš„æ¨¡å‹è¿›è¡Œè¯­éŸ³è¯†åˆ«
    """
    api_key = st.session_state.api_keys.get("OpenAI", "")
    if not api_key:
        st.error("è¯·æä¾› OpenAI API å¯†é’¥ä»¥è¿›è¡Œè¯­éŸ³è¯†åˆ«ï¼")
        return None
    
    try:
        # åˆ›å»º OpenAI å®¢æˆ·ç«¯
        client = OpenAI(api_key=api_key)
        
        # å°†éŸ³é¢‘æ•°æ®è½¬æ¢ä¸ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as temp_file:
            temp_file.write(audio_bytes)
            temp_file_path = temp_file.name
        
        with open(temp_file_path, 'rb') as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file
            )
        
        os.unlink(temp_file_path)  # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        return transcript.text
        
    except Exception as e:
        st.error(f"è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼š{str(e)}")
        return None

def perform_text_summary(text):
    """
    ä½¿ç”¨å½“å‰é€‰æ‹©çš„æ¨¡å‹å¯¹æ–‡æœ¬è¿›è¡Œæ€»ç»“
    """
    try:
        summary_prompt = f"è¯·å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œç®€æ˜æ‰¼è¦çš„æ€»ç»“ï¼š\n\n{text}"
        response = call_model_api(summary_prompt, st.session_state.selected_model)
        return response
    except Exception as e:
        st.error(f"æ–‡æœ¬æ€»ç»“å¤±è´¥ï¼š{str(e)}")
        return None

def retrieve_relevant_content(query):
    """
    åˆ©ç”¨ langchain å°è£…çš„å‘é‡åº“æ£€ç´¢ä¸æŸ¥è¯¢ç›¸å…³çš„æ–‡æ¡£ï¼Œ
    è¿”å›åŒ…å«æ¥æºä¿¡æ¯çš„åˆ—è¡¨ã€‚
    """
    vectorstore = get_vector_store()
    try:
        results = vectorstore.similarity_search(query, k=3)
    except Exception as e:
        st.error(f"æ£€ç´¢æ—¶å‡ºç°é”™è¯¯: {str(e)}")
        return []
    # æå–æ–‡æ¡£ metadata ä¸­çš„ "source" ä¿¡æ¯ï¼›å¦‚æœä¸å­˜åœ¨åˆ™è¿”å› "æœªçŸ¥æ¥æº"
    return [doc.metadata.get("source", "æœªçŸ¥æ¥æº") for doc in results]

def fetch_url_content(url):
    """è·å–ç½‘é¡µå†…å®¹å¹¶æå–æœ‰æ•ˆæ–‡æœ¬"""
    try:
        # æ·»åŠ è¯·æ±‚å¤´ï¼Œæ¨¡æ‹Ÿæµè§ˆå™¨è®¿é—®
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(url, headers=headers, verify=False, timeout=10)
        response.raise_for_status()
        
        # ä½¿ç”¨ BeautifulSoup æå–æ–‡æœ¬å†…å®¹
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # ç§»é™¤è„šæœ¬å’Œæ ·å¼å…ƒç´ 
        for script in soup(["script", "style"]):
            script.decompose()
        
        # è·å–æ–‡æœ¬å¹¶å¤„ç†
        text = soup.get_text()
        lines = (line.strip() for line in text.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        text = ' '.join(chunk for chunk in chunks if chunk)
        
        return text
    except Exception as e:
        st.error(f"è·å–ç½‘é¡µå†…å®¹å¤±è´¥ï¼š{str(e)}")
        return None

def clear_vector_store():
    """æ¸…é™¤å‘é‡æ•°æ®åº“ä¸­çš„æ‰€æœ‰æ•°æ®"""
    try:
        # è·å–å‘é‡å­˜å‚¨å®ä¾‹
        vectorstore = get_vector_store()
        if vectorstore:
            # åˆ é™¤é›†åˆä¸­çš„æ‰€æœ‰æ•°æ®
            vectorstore.delete_collection()
            # é‡æ–°åˆ›å»ºç©ºé›†åˆ
            vectorstore = get_vector_store()
            # æ¸…ç©ºä¼šè¯çŠ¶æ€ä¸­çš„æ•°æ®è®°å½•
            st.session_state.rag_data = []
            return True
    except Exception as e:
        st.error(f"æ¸…é™¤å‘é‡æ•°æ®åº“å¤±è´¥ï¼š{str(e)}")
        return False

def clean_text(text):
    """æ¸…ç†æ–‡æœ¬å†…å®¹"""
    if not text:
        return ""
    # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
    text = re.sub(r'\s+', ' ', text).strip()
    # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™è´§å¸ç¬¦å·
    text = re.sub(r'[^\w\s\u4e00-\u9fff,.?!ï¼Œã€‚ï¼Ÿï¼:ï¼š;ï¼›""''()ï¼ˆï¼‰ã€Šã€‹<>Â¥$â‚¬Â£%]', '', text)
    return text

def is_financial_domain(url):
    """åˆ¤æ–­æ˜¯å¦ä¸ºè´¢ç»é‡‘èç›¸å…³çš„é«˜è´¨é‡åŸŸå"""
    try:
        domain = urlparse(url).netloc.lower()
        
        # è´¢ç»é‡‘èç½‘ç«™ä¼˜å…ˆçº§
        financial_domains = {
            # å®˜æ–¹æœºæ„
            'pbc.gov.cn': 10,     # ä¸­å›½äººæ°‘é“¶è¡Œ
            'csrc.gov.cn': 10,    # ä¸­å›½è¯ç›‘ä¼š
            'safe.gov.cn': 10,    # å¤–æ±‡ç®¡ç†å±€
            'stats.gov.cn': 10,   # å›½å®¶ç»Ÿè®¡å±€
            'mof.gov.cn': 10,     # è´¢æ”¿éƒ¨
            
            # äº¤æ˜“æ‰€
            'sse.com.cn': 9,      # ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€
            'szse.cn': 9,         # æ·±åœ³è¯åˆ¸äº¤æ˜“æ‰€
            'cffex.com.cn': 9,    # ä¸­å›½é‡‘èæœŸè´§äº¤æ˜“æ‰€
            
            # é‡‘èé—¨æˆ·ç½‘ç«™
            'eastmoney.com': 8,   # ä¸œæ–¹è´¢å¯Œ
            'finance.sina.com.cn': 8,  # æ–°æµªè´¢ç»
            'caixin.com': 8,      # è´¢æ–°ç½‘
            'yicai.com': 8,       # ç¬¬ä¸€è´¢ç»
            'stcn.com': 8,        # è¯åˆ¸æ—¶æŠ¥ç½‘
            'cnstock.com': 8,     # ä¸­å›½è¯åˆ¸ç½‘
            '21jingji.com': 8,    # 21ä¸–çºªç»æµç½‘
            
            # è´¢ç»åª’ä½“
            'bloomberg.cn': 8,     # å½­åš
            'ftchinese.com': 8,   # FTä¸­æ–‡ç½‘
            'nbd.com.cn': 7,      # æ¯æ—¥ç»æµæ–°é—»
            'ce.cn': 7,           # ä¸­å›½ç»æµç½‘
            'jrj.com.cn': 7,      # é‡‘èç•Œ
            'hexun.com': 7,       # å’Œè®¯ç½‘
            
            # ç ”ç©¶æœºæ„
            'cfets.org.cn': 7,    # ä¸­å›½å¤–æ±‡äº¤æ˜“ä¸­å¿ƒ
            'chinabond.com.cn': 7, # ä¸­å›½å€ºåˆ¸ä¿¡æ¯ç½‘
            'shibor.org': 7,      # Shiborå®˜ç½‘
            
            # å›½é™…é‡‘èç½‘ç«™
            'reuters.com': 8,      # è·¯é€ç¤¾
            'bloomberg.com': 8,    # å½­åš
            'wsj.com': 8,         # åå°”è¡—æ—¥æŠ¥
            'ft.com': 8,          # é‡‘èæ—¶æŠ¥
            'economist.com': 8,    # ç»æµå­¦äºº
            
            # å…¶ä»–ç›¸å…³ç½‘ç«™
            'investing.com': 7,    # è‹±ä¸ºè´¢æƒ…
            'marketwatch.com': 7,  # å¸‚åœºè§‚å¯Ÿ
            'cnfol.com': 6,       # ä¸­é‡‘åœ¨çº¿
            'stockstar.com': 6,   # è¯åˆ¸ä¹‹æ˜Ÿ
            '10jqka.com.cn': 6,   # åŒèŠ±é¡ºè´¢ç»
        }
        
        # æ£€æŸ¥åŸŸåä¼˜å…ˆçº§
        for known_domain, priority in financial_domains.items():
            if known_domain in domain:
                return priority
                
        return 0  # éé‡‘èç½‘ç«™è¿”å›0ä¼˜å…ˆçº§
    except:
        return 0

def perform_web_search(query, max_results=10):
    """æ‰§è¡Œä¼˜åŒ–çš„è´¢ç»é‡‘èæœç´¢"""
    try:
        # ä¼˜åŒ–æœç´¢æŸ¥è¯¢
        financial_keywords = ['é‡‘è', 'è´¢ç»', 'ç»æµ', 'è‚¡å¸‚', 'åŸºé‡‘', 'å€ºåˆ¸', 'å¤–æ±‡', 
                            'æœŸè´§', 'ç†è´¢', 'æŠ•èµ„', 'è¯åˆ¸', 'é“¶è¡Œ', 'ä¿é™©', 'é‡‘ä»·']
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ è´¢ç»å…³é”®è¯
        if not any(keyword in query for keyword in financial_keywords):
            # æ·»åŠ è´¢ç»ç›¸å…³å…³é”®è¯ä»¥æé«˜ç›¸å…³æ€§
            optimized_query = query + ' è´¢ç»'
        else:
            optimized_query = query
        
        # ä½¿ç”¨ DuckDuckGoSearchRun è¿›è¡Œä¸»æœç´¢
        search_tool = DuckDuckGoSearchRun()
        initial_results = search_tool.run(optimized_query)
        
        # ä½¿ç”¨ DDGS è¿›è¡Œè¡¥å……æœç´¢
        with DDGS() as ddgs:
            detailed_results = list(ddgs.text(
                optimized_query,
                max_results=max_results,
                region='cn-zh',
                safesearch='moderate',
                timelimit='m'  # é™åˆ¶æœ€è¿‘ä¸€ä¸ªæœˆçš„ç»“æœï¼Œä¿è¯ä¿¡æ¯æ—¶æ•ˆæ€§
            ))
        
        # ç»“æœå¤„ç†å’Œæ’åº
        processed_results = []
        seen_content = set()
        
        if detailed_results:
            for result in detailed_results:
                title = clean_text(result.get('title', ''))
                snippet = clean_text(result.get('body', ''))
                link = result.get('link', '')
                
                # å†…å®¹å»é‡æ£€æŸ¥
                content_hash = f"{title}_{snippet}"
                if content_hash in seen_content:
                    continue
                seen_content.add(content_hash)
                
                # è®¡ç®—åŸŸåè´¨é‡åˆ†æ•°
                domain_score = is_financial_domain(link)
                
                # è®¡ç®—å†…å®¹ç›¸å…³æ€§åˆ†æ•°
                relevance_score = sum(1 for word in query.lower().split() 
                                    if word in title.lower() or word in snippet.lower())
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«è´¢ç»å…³é”®è¯
                financial_relevance = sum(1 for keyword in financial_keywords 
                                        if keyword in title or keyword in snippet)
                
                # ç»¼åˆè¯„åˆ†
                total_score = domain_score * 3 + relevance_score * 2 + financial_relevance * 2
                
                if domain_score > 0 or financial_relevance > 0:  # åªä¿ç•™é‡‘èç›¸å…³ç½‘ç«™çš„å†…å®¹
                    processed_results.append({
                        'title': title,
                        'snippet': snippet,
                        'link': link,
                        'score': total_score
                    })
        
        # æŒ‰ç»¼åˆè¯„åˆ†æ’åº
        processed_results.sort(key=lambda x: x['score'], reverse=True)
        
        # æ„å»ºæœ€ç»ˆå“åº”
        final_response = "è´¢ç»ç›¸å…³æœç´¢ç»“æœï¼š\n\n"
        
        # æ·»åŠ åˆæ­¥æœç´¢ç»“æœ
        if initial_results and any(keyword in initial_results.lower() for keyword in financial_keywords):
            final_response += f"{initial_results}\n\n"
        
        # æ·»åŠ é«˜è´¨é‡è¡¥å……ç»“æœ
        if processed_results:
            final_response += "è¡¥å……ä¿¡æ¯ï¼š\n"
            for idx, result in enumerate(processed_results[:5], 1):
                if result['score'] > 4:  # æé«˜æ˜¾ç¤ºé˜ˆå€¼ï¼Œç¡®ä¿é«˜è´¨é‡ç»“æœ
                    final_response += f"{idx}. **{result['title']}**\n"
                    final_response += f"   {result['snippet']}\n"
                    final_response += f"   æ¥æºï¼š[{urlparse(result['link']).netloc}]({result['link']})\n\n"
        
        return final_response.strip()
    
    except Exception as e:
        st.error(f"è´¢ç»ä¿¡æ¯æœç´¢å¤±è´¥: {str(e)}")
        return None

def get_search_response(query):
    """ç”Ÿæˆä¼˜åŒ–çš„è´¢ç»æœç´¢å“åº”ï¼Œå¹¶ç”±å¤§æ¨¡å‹æ€»ç»“"""
    try:
        # è·å–æœç´¢ç»“æœ
        search_results = perform_web_search(query)
        if not search_results:
            return "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„è´¢ç»ä¿¡æ¯ã€‚"
        
        # æ„å»ºæç¤ºè¯ï¼Œè®©å¤§æ¨¡å‹è¿›è¡Œæ€»ç»“
        summary_prompt = f"""
è¯·é’ˆå¯¹ä»¥ä¸‹ç”¨æˆ·é—®é¢˜å’Œæœç´¢ç»“æœï¼Œè¿›è¡Œä¸“ä¸šçš„æ€»ç»“åˆ†æï¼š

ç”¨æˆ·é—®é¢˜ï¼š{query}

æœç´¢ç»“æœï¼š
{search_results}

è¯·ä½ ä½œä¸ºé‡‘èä¸“å®¶ï¼š
1. æå–è¦ç‚¹ï¼Œç›´æ¥å›ç­”ç”¨æˆ·çš„æ ¸å¿ƒé—®é¢˜
2. ç¡®ä¿ä¿¡æ¯çš„å‡†ç¡®æ€§å’Œæ—¶æ•ˆæ€§
3. å¦‚æœ‰å¿…è¦ï¼Œç»™å‡ºä¸“ä¸šçš„å»ºè®®æˆ–é£é™©æç¤º
4. ä¿æŒç®€æ´æ¸…æ™°ï¼Œçªå‡ºé‡ç‚¹

è¯·ä»¥ä¸“ä¸šã€å®¢è§‚çš„å£å»å›ç­”ã€‚
"""
        # è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œæ€»ç»“
        summary = call_model_api(summary_prompt, st.session_state.selected_model)
        
        # æ„å»ºæœ€ç»ˆå“åº”
        response = "ğŸ“Š **æ ¸å¿ƒå›ç­”ï¼š**\n\n"
        response += f"{summary}\n\n"
        response += "---\n"
        response += "ğŸ” **è¯¦ç»†æœç´¢ç»“æœï¼š**\n\n"
        response += f"{search_results}\n\n"
        response += "---\n"
        response += "*ä»¥ä¸Šä¿¡æ¯æ¥è‡ªæƒå¨è´¢ç»é‡‘èç½‘ç«™ï¼Œå¹¶ç»AIåˆ†ææ•´ç†ã€‚è¯·æ³¨æ„ä¿¡æ¯æ—¶æ•ˆæ€§ï¼Œå»ºè®®è¿›ä¸€æ­¥æ ¸å®å…·ä½“æ•°æ®ã€‚*"
        
        return response

    except Exception as e:
        st.error(f"ç”Ÿæˆå›ç­”å¤±è´¥ï¼š{str(e)}")
        return None

def process_urls(urls_input):
    """å¤„ç†è¾“å…¥çš„ç½‘å€ï¼Œæå–å†…å®¹å¹¶æ·»åŠ åˆ° RAG çŸ¥è¯†åº“"""
    urls = [url.strip() for url in urls_input.split('\n') if url.strip()]
    
    for url in urls:
        with st.spinner(f"æ­£åœ¨å¤„ç†ç½‘å€ï¼š{url}"):
            try:
                # å‘é€ HTTP è¯·æ±‚è·å–ç½‘é¡µå†…å®¹
                response = requests.get(url, timeout=10)
                response.raise_for_status()  # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ
                
                # ä½¿ç”¨ BeautifulSoup è§£æç½‘é¡µå†…å®¹
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # ç§»é™¤è„šæœ¬å’Œæ ·å¼å…ƒç´ 
                for script in soup(["script", "style"]):
                    script.decompose()
                
                # æå–æ–‡æœ¬å†…å®¹
                text = soup.get_text()
                
                # æ¸…ç†æ–‡æœ¬ï¼ˆç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦ï¼‰
                lines = (line.strip() for line in text.splitlines())
                chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
                text = ' '.join(chunk for chunk in chunks if chunk)
                
                if text:
                    # å°†ç½‘é¡µå†…å®¹æ·»åŠ åˆ° RAG çŸ¥è¯†åº“
                    if rag_index_document(text, url):
                        st.session_state.rag_data.append(url)
                        st.success(f"âœ… ç½‘å€ {url} å·²æˆåŠŸåŠ å…¥çŸ¥è¯†åº“")
                else:
                    st.warning(f"âš ï¸ ç½‘å€ {url} æœªæå–åˆ°æœ‰æ•ˆå†…å®¹")
                    
            except requests.RequestException as e:
                st.error(f"âŒ è®¿é—®ç½‘å€ {url} å¤±è´¥ï¼š{str(e)}")
            except Exception as e:
                st.error(f"âŒ å¤„ç†ç½‘å€ {url} æ—¶å‡ºé”™ï¼š{str(e)}")

# ====================
# ä¾§è¾¹æ é…ç½®
# ====================
with st.sidebar:
    st.header("âš™ï¸ ç³»ç»Ÿè®¾ç½®")

    # API å¯†é’¥ç®¡ç†
    st.subheader("APIå¯†é’¥ç®¡ç†")
    api_key_input = st.text_input(
        "è¾“å…¥ API å¯†é’¥",
        help="è¾“å…¥ä¸€ä¸ªAPIå¯†é’¥ï¼Œç”¨äºè®¿é—®æ‰€é€‰æ¨¡å‹",
        type="password"
    )
    api_keys_to_set = {
        "è±†åŒ…": api_key_input,
        "Kimi(è§†è§‰ç†è§£)": api_key_input,
        "DeepSeek": api_key_input,
        "é€šä¹‰åƒé—®": api_key_input,
        "æ–‡å¿ƒä¸€è¨€": api_key_input,
        "æ™ºè°±æ¸…è¨€": api_key_input,
        "MiniMax": api_key_input,
        "OpenAI": api_key_input
    }
    if api_key_input:
        for key, value in api_keys_to_set.items():
            st.session_state.api_keys[key] = value
        st.success("API å¯†é’¥å·²ä¿å­˜ï¼")

    # æ¨¡å‹é€‰æ‹©
    model_options = {
        "è±†åŒ…": ["ep-20250128163906-p4tb5"],
        "DeepSeek-V3": ["deepseek-chat"],
        "é€šä¹‰åƒé—®": ["qwen-plus"],
        "æ–‡å¿ƒä¸€è¨€": ["ERNIE-Bot"],
        "æ™ºè°±æ¸…è¨€": ["glm-4"],
        "MiniMax": ["abab5.5-chat"],
        "DALL-E(æ–‡ç”Ÿå›¾)": ["dall-e-3"],
        "DeepSeek-R1(æ·±åº¦æ¨ç†)": ["deepseek-reasoner"],
        "o1(æ·±åº¦æ¨ç†)": ["o1-mini"],
        "Kimi(è§†è§‰ç†è§£)": ["moonshot-v1-8k-vision-preview"],
        "GPTs(èŠå¤©ã€è¯­éŸ³è¯†åˆ«)": ["gpt-4"]
    }

    st.session_state.selected_model = st.selectbox(
        "é€‰æ‹©å¤§æ¨¡å‹",
        list(model_options.keys()),
        index=0
    )

    # åŠŸèƒ½é€‰æ‹©
    function_options = [
        "æ™ºèƒ½é—®ç­”",
        "æ–‡æœ¬ç¿»è¯‘",
        "æ–‡æœ¬æ€»ç»“",
        "æ–‡ç”Ÿå›¾",
        "æ·±åº¦æ¨ç†",
        "è§†è§‰ç†è§£",
        "è¯­éŸ³è¯†åˆ«"
    ]
    st.session_state.selected_function = st.selectbox(
        "é€‰æ‹©åŠŸèƒ½",
        function_options,
        index=0
    )

    # é€šç”¨å‚æ•°
    col1, col2 = st.columns(2)
    with col1:
        st.session_state.temperature = st.slider("åˆ›æ„åº¦", 0.0, 1.0, 0.5, 0.1)
    with col2:
        st.session_state.max_tokens = st.slider("å“åº”é•¿åº¦", 100, 4096, 2048, 100)

    # è”ç½‘æœç´¢åŠŸèƒ½æŒ‰é’®
    if st.button(
        f"ğŸŒ è”ç½‘æœç´¢[{('on' if st.session_state.search_enabled else 'off')}]",
        use_container_width=True
    ):
        st.session_state.search_enabled = not st.session_state.search_enabled
        st.rerun()

    # RAG åŠŸèƒ½æŒ‰é’®
    if st.button(
        f"ğŸ“š RAG åŠŸèƒ½[{('on' if st.session_state.rag_enabled else 'off')}]",
        use_container_width=True
    ):
        st.session_state.rag_enabled = not st.session_state.rag_enabled
        st.rerun()

    # API æµ‹è¯•åŠŸèƒ½
    st.subheader("API æµ‹è¯•")
    if st.button("ğŸ” æµ‹è¯• API è¿æ¥"):
        if not st.session_state.api_keys:
            st.error("è¯·å…ˆè¾“å…¥ API å¯†é’¥ï¼")
        else:
            with st.spinner("æ­£åœ¨æµ‹è¯• API è¿æ¥..."):
                try:
                    test_prompt = "æ‚¨å¥½ï¼Œè¯·å›å¤'è¿æ¥æˆåŠŸ'ã€‚"
                    response = call_model_api(test_prompt, st.session_state.selected_model)
                    if response:
                        st.success(f"API è¿æ¥æˆåŠŸï¼æ¨¡å‹å›å¤ï¼š{response}")
                    else:
                        st.error("API è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥å¯†é’¥å’Œç½‘ç»œè®¾ç½®ã€‚")
                except Exception as e:
                    st.error(f"API æµ‹è¯•å¤±è´¥ï¼š{str(e)}")

    if st.button("ğŸ§¹ æ¸…ç©ºå¯¹è¯å†å²"):
        st.session_state.messages = []
        st.rerun()

    # æ·»åŠ æ¸…ç©ºçŸ¥è¯†åº“æŒ‰é’®
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºçŸ¥è¯†åº“", help="æ¸…é™¤æ‰€æœ‰å·²ä¸Šä¼ çš„æ–‡ä»¶å’Œç½‘å€æ•°æ®"):
        if st.session_state.rag_enabled:
            with st.spinner("æ­£åœ¨æ¸…ç©ºçŸ¥è¯†åº“..."):
                if clear_vector_store():
                    st.success("âœ… çŸ¥è¯†åº“å·²æ¸…ç©º")
                    st.session_state.rag_data = []
                    st.rerun()
                else:
                    st.error("âŒ æ¸…ç©ºçŸ¥è¯†åº“å¤±è´¥")
        else:
            st.warning("è¯·å…ˆå¼€å¯ RAG åŠŸèƒ½")

    # æ›´æ–°è¯´æ˜
    st.subheader("æ›´æ–°è¯´æ˜")
    st.write("- æ–°å¢ï¼šæ„å»ºç§äººçŸ¥è¯†åº“(RAG)åŠŸèƒ½")
    st.write("- é¢„å‘Šï¼šåç»­å°†å¢åŠ  AI agent ç­‰åŠŸèƒ½")

    # åœ¨ä¸»ç•Œé¢çš„ä¾§è¾¹æ æ·»åŠ  ChromaDB é…ç½®
    if st.session_state.rag_enabled:
        configure_chromadb()

# ====================
# ä¸»ç•Œé¢å¸ƒå±€
# ====================
st.title("ğŸ¤– å¤šæ¨¡å‹æ™ºèƒ½åŠ©æ‰‹2.0")

# æ–‡ä»¶å’Œç½‘å€ä¸Šä¼ åŒºåŸŸ
st.markdown("### ğŸ“ æ–‡ä»¶ä¸Šä¼ ")

# RAG æ¨¡å¼ï¼šå¤šæ–‡ä»¶ä¸Šä¼ å’Œç½‘å€è¾“å…¥
if st.session_state.rag_enabled:
    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_files = st.file_uploader(
        "æ”¯æŒå¤šä¸ªæ–‡ä»¶ä¸Šä¼ ï¼ˆå»ºè®®ä¸è¶…è¿‡5ä¸ªï¼‰",
        accept_multiple_files=True,
        type=["txt", "pdf", "docx", "doc", "csv", "xlsx", "xls"],
        key="multi_file_uploader"
    )
    
    # ç½‘å€è¾“å…¥
    st.markdown("### ğŸ”— ç½‘å€ä¸Šä¼ ")
    urls_input = st.text_area(
        "æ¯è¡Œè¾“å…¥ä¸€ä¸ªç½‘å€ï¼ˆå»ºè®®ä¸è¶…è¿‡5ä¸ªï¼‰",
        height=100,
        key="urls_input",
        placeholder="https://example1.com\nhttps://example2.com"
    )
    
    # æäº¤æŒ‰é’®
    if st.button("ğŸ“¤ æäº¤æ–‡ä»¶å’Œç½‘å€"):
        if not uploaded_files and not urls_input.strip():
            st.warning("è¯·è‡³å°‘ä¸Šä¼ ä¸€ä¸ªæ–‡ä»¶æˆ–è¾“å…¥ä¸€ä¸ªç½‘å€ã€‚")
        else:
            success_count = 0
            # å¤„ç†æ–‡ä»¶
            if uploaded_files:
                if len(uploaded_files) > 5:
                    st.warning("âš ï¸ æ–‡ä»¶æ•°é‡è¶…è¿‡5ä¸ªï¼Œå»ºè®®å‡å°‘æ–‡ä»¶æ•°é‡ä»¥è·å¾—æ›´å¥½çš„å¤„ç†æ•ˆæœã€‚")
                
                for file in uploaded_files:
                    with st.spinner(f"æ­£åœ¨å¤„ç†æ–‡ä»¶ï¼š{file.name}"):
                        try:
                            content = extract_text_from_file(file)
                            if content:
                                if rag_index_document(content, file.name):
                                    success_count += 1
                                    st.session_state.rag_data.append(file.name)
                                    st.success(f"âœ… æ–‡ä»¶ {file.name} å·²æˆåŠŸåŠ å…¥çŸ¥è¯†åº“")
                            else:
                                st.error(f"âŒ æ— æ³•æå–æ–‡ä»¶å†…å®¹ï¼š{file.name}")
                        except Exception as e:
                            st.error(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥ï¼š{str(e)}")
            
            # å¤„ç†ç½‘å€
            if urls_input.strip():
                process_urls(urls_input)

            if success_count > 0:
                st.success(f"âœ… å…±æˆåŠŸå¤„ç† {success_count} ä¸ªæ–‡ä»¶/ç½‘å€")
                # å¼ºåˆ¶åˆ·æ–°å‘é‡åº“å®ä¾‹
                st.session_state.vector_store = None
                # é‡æ–°åŠ è½½å‘é‡åº“
                get_vector_store()
            else:
                st.error("âŒ æœªèƒ½æˆåŠŸå¤„ç†ä»»ä½•æ–‡ä»¶æˆ–ç½‘å€")

# é RAG æ¨¡å¼ï¼šå•æ–‡ä»¶ä¸Šä¼ å¹¶ç«‹å³å¤„ç†
else:
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ å•ä¸ªæ–‡ä»¶è¿›è¡Œåˆ†æ",
        accept_multiple_files=False,
        type=["txt", "pdf", "docx", "doc", "jpg", "jpeg", "png", "mp3", "wav", "m4a"],
        key="single_file_uploader"
    )
    
    if uploaded_file:
        file_type = uploaded_file.name.split('.')[-1].lower()
        
        try:
            # 1. è¯­éŸ³è¯†åˆ«ï¼ˆGPTsï¼‰
            if file_type in ["mp3", "wav", "m4a"]:
                with st.spinner("ğŸµ æ­£åœ¨è¿›è¡Œè¯­éŸ³è¯†åˆ«..."):
                    if "OpenAI" not in st.session_state.api_keys:
                        st.error("è¯·å…ˆé…ç½® OpenAI API å¯†é’¥")
                    else:
                        client = OpenAI(api_key=st.session_state.api_keys["OpenAI"])
                        with tempfile.NamedTemporaryFile(delete=False, suffix=f".{file_type}") as tmp_file:
                            tmp_file.write(uploaded_file.getvalue())
                            tmp_file.flush()
                            
                            with open(tmp_file.name, "rb") as audio_file:
                                transcription = client.audio.transcriptions.create(
                                    model="whisper-1",
                                    file=audio_file,
                                    language="zh"
                                )
                        
                        st.success("âœ… è¯­éŸ³è¯†åˆ«å®Œæˆ")
                        with st.chat_message("assistant"):
                            st.markdown(f"**è¯­éŸ³è¯†åˆ«ç»“æœï¼š**\n\n{transcription.text}")
                        st.session_state.messages.append({
                            "role": "assistant",
                            "content": f"è¯­éŸ³æ–‡ä»¶ {uploaded_file.name} çš„è¯†åˆ«ç»“æœï¼š\n\n{transcription.text}",
                            "type": "text"
                        })
            
            # 2. å›¾ç‰‡åˆ†æï¼ˆmoonshot-v1-8k-vision-previewï¼‰
            elif file_type in ["jpg", "jpeg", "png"]:
                with st.spinner("ğŸ–¼ï¸ æ­£åœ¨åˆ†æå›¾ç‰‡..."):
                    if "Kimi(è§†è§‰ç†è§£)" not in st.session_state.api_keys:
                        st.error("è¯·å…ˆé…ç½® Kimi(è§†è§‰ç†è§£) API å¯†é’¥")
                    else:
                        image_content = uploaded_file.getvalue()
                        encoded_image = base64.b64encode(image_content).decode('utf-8')
                        
                        headers = {
                            "Content-Type": "application/json",
                            "Authorization": f"Bearer {st.session_state.api_keys['Kimi(è§†è§‰ç†è§£)']}"
                        }
                        
                        payload = {
                            "model": "moonshot-v1-8k-vision-preview",
                            "messages": [
                                {
                                    "role": "user",
                                    "content": [
                                        {
                                            "type": "text",
                                            "text": "è¯·è¯¦ç»†åˆ†æè¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼ŒåŒ…æ‹¬ä¸»è¦å¯¹è±¡ã€åœºæ™¯ã€ç»†èŠ‚ç­‰æ–¹é¢ã€‚"
                                        },
                                        {
                                            "type": "image_url",
                                            "image_url": {
                                                "url": f"data:image/jpeg;base64,{encoded_image}"
                                            }
                                        }
                                    ]
                                }
                            ]
                        }
                        
                        response = requests.post(
                            "https://api.moonshot.cn/v1/chat/completions",
                            json=payload,
                            headers=headers
                        )
                        
                        if response.status_code == 200:
                            result = response.json()["choices"][0]["message"]["content"]
                            st.success("âœ… å›¾ç‰‡åˆ†æå®Œæˆ")
                            with st.chat_message("assistant"):
                                st.markdown(f"**å›¾ç‰‡åˆ†æç»“æœï¼š**\n\n{result}")
                            st.session_state.messages.append({
                                "role": "assistant",
                                "content": f"å›¾ç‰‡ {uploaded_file.name} çš„åˆ†æç»“æœï¼š\n\n{result}",
                                "type": "text"
                            })
                        else:
                            st.error(f"âŒ å›¾ç‰‡åˆ†æå¤±è´¥ï¼š{response.text}")
            
            # 3. æ–‡æ¡£æ€»ç»“
            elif file_type in ["txt", "pdf", "docx", "doc"]:
                with st.spinner("ğŸ“„ æ­£åœ¨æ€»ç»“æ–‡æ¡£..."):
                    content = extract_text_from_file(uploaded_file)
                    if content:
                        summary_prompt = f"""è¯·å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œä¸“ä¸šçš„æ€»ç»“åˆ†æï¼š

æ–‡æœ¬å†…å®¹ï¼š
{content}

è¯·ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢è¿›è¡Œæ€»ç»“ï¼š
1. æ ¸å¿ƒè¦ç‚¹ï¼ˆæœ€é‡è¦çš„2-3ä¸ªå…³é”®ä¿¡æ¯ï¼‰
2. ä¸»è¦å†…å®¹æ¦‚è¿°
3. é‡è¦ç»“è®ºæˆ–å‘ç°
4. ç›¸å…³å»ºè®®ï¼ˆå¦‚æœé€‚ç”¨ï¼‰

è¯·ç”¨æ¸…æ™°ã€ä¸“ä¸šçš„è¯­è¨€ç»„ç»‡å›ç­”ã€‚"""

                        summary = call_model_api(summary_prompt, st.session_state.selected_model)
                        if summary:
                            st.success("âœ… æ–‡æ¡£æ€»ç»“å®Œæˆ")
                            with st.chat_message("assistant"):
                                st.markdown(f"**æ–‡æ¡£æ€»ç»“ç»“æœï¼š**\n\n{summary}")
                            st.session_state.messages.append({
                                "role": "assistant",
                                "content": f"æ–‡æ¡£ {uploaded_file.name} çš„æ€»ç»“ï¼š\n\n{summary}",
                                "type": "text"
                            })
            
            else:
                st.warning(f"âš ï¸ ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼š{file_type}")
        
        except Exception as e:
            st.error(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥ï¼š{str(e)}")
            import traceback
            st.error(f"è¯¦ç»†é”™è¯¯ï¼š{traceback.format_exc()}")

# ====================
# ç”¨æˆ·é—®é¢˜è¾“å…¥åŒºåŸŸ
with st.container():
    # åˆå§‹æç¤ºï¼ˆä»…åœ¨å¯¹è¯è®°å½•ä¸ºç©ºæ—¶æ˜¾ç¤ºï¼‰
    if not st.session_state.messages:
        with st.chat_message("assistant"):
            st.write("æ‚¨å¥½ï¼æˆ‘æ˜¯å¤šæ¨¡å‹æ™ºèƒ½åŠ©æ‰‹ï¼Œè¯·é€‰æ‹©æ¨¡å‹å’ŒåŠŸèƒ½å¼€å§‹äº¤äº’ã€‚")
            
    user_input = st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜æˆ–æŒ‡ä»¤...", key="user_input")
    
    if user_input:
        with st.chat_message("user"):
            st.write(user_input)
        
        st.session_state.messages.append({"role": "user", "content": user_input, "type": "text"})
        
        with st.spinner("ğŸ§  æ­£åœ¨æ€è€ƒ..."):
            combined_response = ""
            
            # è”ç½‘æœç´¢éƒ¨åˆ†
            if st.session_state.search_enabled:
                try:
                    search_response = get_search_response(user_input)
                    if search_response:
                        combined_response += search_response + "\n\n"
                except Exception as e:
                    st.error(f"æœç´¢è¿‡ç¨‹å‡ºé”™ï¼š{str(e)}")
            
            # RAG æ£€ç´¢éƒ¨åˆ†
            if st.session_state.rag_enabled:
                try:
                    rag_response = rag_generate_response(user_input)
                    if rag_response:
                        combined_response += "ğŸ“š **çŸ¥è¯†åº“æ£€ç´¢ç»“æœï¼š**\n\n" + rag_response + "\n\n"
                except Exception as e:
                    st.error(f"RAG æ£€ç´¢å‡ºé”™ï¼š{str(e)}")
            
            # å¦‚æœä¸¤ä¸ªåŠŸèƒ½éƒ½æœªå¼€å¯ï¼Œä½¿ç”¨æ™®é€šå¯¹è¯æ¨¡å¼
            if not (st.session_state.search_enabled or st.session_state.rag_enabled):
                response = call_model_api(user_input, st.session_state.selected_model)
                if response:
                    combined_response = response
            
            # æ˜¾ç¤ºç»„åˆåçš„å›ç­”
            if combined_response:
                with st.chat_message("assistant"):
                    st.markdown(combined_response)
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": combined_response,
                    "type": "text"
                })
            else:
                st.error("æœªèƒ½è·å–åˆ°ä»»ä½•ç»“æœï¼Œè¯·é‡è¯•ã€‚")

# ====================
# æ˜¾ç¤ºå†å²å¯¹è¯è®°å½•
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        if msg.get("type") == "image":
            st.image(msg["content"])
        else:
            st.write(msg["content"])



